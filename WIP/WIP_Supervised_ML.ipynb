{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import items\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>...</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>declined to answer</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>75.0</td>\n",
       "      <td>29592</td>\n",
       "      <td>...</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>70.0</td>\n",
       "      <td>48630</td>\n",
       "      <td>...</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>masters program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>60812</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>declined to answer</td>\n",
       "      <td>white</td>\n",
       "      <td>71.0</td>\n",
       "      <td>18578</td>\n",
       "      <td>...</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn&amp;rsquo;t want kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>66.0</td>\n",
       "      <td>94691</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>59941</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>college/university</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>16612</td>\n",
       "      <td>...</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>has kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>has dogs</td>\n",
       "      <td>catholicism but not too serious about it</td>\n",
       "      <td>f</td>\n",
       "      <td>cancer and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>59942</td>\n",
       "      <td>24</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>declined to answer</td>\n",
       "      <td>white, other</td>\n",
       "      <td>72.0</td>\n",
       "      <td>118254</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>m</td>\n",
       "      <td>leo but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>59943</td>\n",
       "      <td>42</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>masters program</td>\n",
       "      <td>asian</td>\n",
       "      <td>71.0</td>\n",
       "      <td>42318</td>\n",
       "      <td>...</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>christianity but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>sagittarius but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>59944</td>\n",
       "      <td>27</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>often</td>\n",
       "      <td>declined to answer</td>\n",
       "      <td>asian, black</td>\n",
       "      <td>73.0</td>\n",
       "      <td>218886</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but wants them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>leo and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>trying to quit</td>\n",
       "      <td>english (fluently), spanish (poorly), chinese ...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>59945</td>\n",
       "      <td>39</td>\n",
       "      <td>average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>masters program</td>\n",
       "      <td>white</td>\n",
       "      <td>68.0</td>\n",
       "      <td>100804</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gay</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>catholicism and laughing about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini and it&amp;rsquo;s fun to think about</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  age       body_type               diet      drinks  \\\n",
       "0               0   22  a little extra  strictly anything    socially   \n",
       "1               1   35         average       mostly other       often   \n",
       "2               2   38            thin           anything    socially   \n",
       "3               3   23            thin         vegetarian    socially   \n",
       "4               4   29        athletic                NaN    socially   \n",
       "...           ...  ...             ...                ...         ...   \n",
       "59941       59941   59             NaN                NaN    socially   \n",
       "59942       59942   24             fit    mostly anything       often   \n",
       "59943       59943   42         average    mostly anything  not at all   \n",
       "59944       59944   27        athletic    mostly anything    socially   \n",
       "59945       59945   39         average                NaN    socially   \n",
       "\n",
       "           drugs           education            ethnicity  height  income  \\\n",
       "0          never  declined to answer         asian, white    75.0   29592   \n",
       "1      sometimes  college/university                white    70.0   48630   \n",
       "2            NaN     masters program                  NaN    68.0   60812   \n",
       "3            NaN  declined to answer                white    71.0   18578   \n",
       "4          never  college/university  asian, black, other    66.0   94691   \n",
       "...          ...                 ...                  ...     ...     ...   \n",
       "59941      never  college/university                  NaN    62.0   16612   \n",
       "59942  sometimes  declined to answer         white, other    72.0  118254   \n",
       "59943      never     masters program                asian    71.0   42318   \n",
       "59944      often  declined to answer         asian, black    73.0  218886   \n",
       "59945        NaN     masters program                white    68.0  100804   \n",
       "\n",
       "       ...                         location  \\\n",
       "0      ...  south san francisco, california   \n",
       "1      ...              oakland, california   \n",
       "2      ...        san francisco, california   \n",
       "3      ...             berkeley, california   \n",
       "4      ...        san francisco, california   \n",
       "...    ...                              ...   \n",
       "59941  ...              oakland, california   \n",
       "59942  ...        san francisco, california   \n",
       "59943  ...  south san francisco, california   \n",
       "59944  ...        san francisco, california   \n",
       "59945  ...        san francisco, california   \n",
       "\n",
       "                                          offspring orientation  \\\n",
       "0      doesn&rsquo;t have kids, but might want them    straight   \n",
       "1      doesn&rsquo;t have kids, but might want them    straight   \n",
       "2                                               NaN    straight   \n",
       "3                           doesn&rsquo;t want kids    straight   \n",
       "4                                               NaN    straight   \n",
       "...                                             ...         ...   \n",
       "59941                                      has kids    straight   \n",
       "59942                       doesn&rsquo;t have kids    straight   \n",
       "59943                       doesn&rsquo;t have kids    straight   \n",
       "59944       doesn&rsquo;t have kids, but wants them    straight   \n",
       "59945                                           NaN         gay   \n",
       "\n",
       "                            pets                                   religion  \\\n",
       "0      likes dogs and likes cats      agnosticism and very serious about it   \n",
       "1      likes dogs and likes cats   agnosticism but not too serious about it   \n",
       "2                       has cats                                        NaN   \n",
       "3                     likes cats                                        NaN   \n",
       "4      likes dogs and likes cats                                        NaN   \n",
       "...                          ...                                        ...   \n",
       "59941                   has dogs   catholicism but not too serious about it   \n",
       "59942  likes dogs and likes cats                                agnosticism   \n",
       "59943                        NaN  christianity but not too serious about it   \n",
       "59944  likes dogs and likes cats   agnosticism but not too serious about it   \n",
       "59945  likes dogs and likes cats          catholicism and laughing about it   \n",
       "\n",
       "      sex                                      sign          smokes  \\\n",
       "0       m                                    gemini       sometimes   \n",
       "1       m                                    cancer              no   \n",
       "2       m        pisces but it doesn&rsquo;t matter              no   \n",
       "3       m                                    pisces              no   \n",
       "4       m                                  aquarius              no   \n",
       "...    ..                                       ...             ...   \n",
       "59941   f  cancer and it&rsquo;s fun to think about              no   \n",
       "59942   m           leo but it doesn&rsquo;t matter              no   \n",
       "59943   m   sagittarius but it doesn&rsquo;t matter              no   \n",
       "59944   m     leo and it&rsquo;s fun to think about  trying to quit   \n",
       "59945   m  gemini and it&rsquo;s fun to think about       sometimes   \n",
       "\n",
       "                                                  speaks     status  \n",
       "0                                                english     single  \n",
       "1      english (fluently), spanish (poorly), french (...     single  \n",
       "2                                   english, french, c++  available  \n",
       "3                               english, german (poorly)     single  \n",
       "4                                                english     single  \n",
       "...                                                  ...        ...  \n",
       "59941                                            english     single  \n",
       "59942                                 english (fluently)     single  \n",
       "59943                                 english (fluently)     single  \n",
       "59944  english (fluently), spanish (poorly), chinese ...     single  \n",
       "59945                                            english     single  \n",
       "\n",
       "[59946 rows x 22 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw data file\n",
    "file_to_load = \"user_profiles.csv\"\n",
    "\n",
    "# Read purchasing file and store into pandas data frame\n",
    "df= pd.read_csv(file_to_load)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>height</th>\n",
       "      <th>sex</th>\n",
       "      <th>smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>75.0</td>\n",
       "      <td>m</td>\n",
       "      <td>sometimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>70.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>66.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59941</th>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>62.0</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>24</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>72.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>42</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>71.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>27</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>often</td>\n",
       "      <td>73.0</td>\n",
       "      <td>m</td>\n",
       "      <td>trying to quit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59945</th>\n",
       "      <td>39</td>\n",
       "      <td>average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>m</td>\n",
       "      <td>sometimes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59946 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age       body_type               diet      drinks      drugs  height  \\\n",
       "0       22  a little extra  strictly anything    socially      never    75.0   \n",
       "1       35         average       mostly other       often  sometimes    70.0   \n",
       "2       38            thin           anything    socially        NaN    68.0   \n",
       "3       23            thin         vegetarian    socially        NaN    71.0   \n",
       "4       29        athletic                NaN    socially      never    66.0   \n",
       "...    ...             ...                ...         ...        ...     ...   \n",
       "59941   59             NaN                NaN    socially      never    62.0   \n",
       "59942   24             fit    mostly anything       often  sometimes    72.0   \n",
       "59943   42         average    mostly anything  not at all      never    71.0   \n",
       "59944   27        athletic    mostly anything    socially      often    73.0   \n",
       "59945   39         average                NaN    socially        NaN    68.0   \n",
       "\n",
       "      sex          smokes  \n",
       "0       m       sometimes  \n",
       "1       m              no  \n",
       "2       m              no  \n",
       "3       m              no  \n",
       "4       m              no  \n",
       "...    ..             ...  \n",
       "59941   f              no  \n",
       "59942   m              no  \n",
       "59943   m              no  \n",
       "59944   m  trying to quit  \n",
       "59945   m       sometimes  \n",
       "\n",
       "[59946 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep columns that will assist on determining body type.\n",
    "\n",
    "working_df = df.drop(columns=['sign', 'speaks', 'status', 'last_online', 'income', 'location', 'job', 'education', 'orientation', 'religion', 'ethnicity'])\n",
    "working_df = working_df.drop(columns=['offspring', 'pets', 'Unnamed: 0'])\n",
    "working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>height</th>\n",
       "      <th>sex</th>\n",
       "      <th>smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>75.0</td>\n",
       "      <td>m</td>\n",
       "      <td>sometimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>70.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>65.0</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>65.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>72.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59935</th>\n",
       "      <td>33</td>\n",
       "      <td>curvy</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>67.0</td>\n",
       "      <td>f</td>\n",
       "      <td>when drinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59936</th>\n",
       "      <td>25</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>61.0</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>24</td>\n",
       "      <td>fit</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>72.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>42</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>71.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>27</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>often</td>\n",
       "      <td>73.0</td>\n",
       "      <td>m</td>\n",
       "      <td>trying to quit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25202 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age       body_type               diet      drinks      drugs  height  \\\n",
       "0       22  a little extra  strictly anything    socially      never    75.0   \n",
       "1       35         average       mostly other       often  sometimes    70.0   \n",
       "7       31         average    mostly anything    socially      never    65.0   \n",
       "9       37        athletic    mostly anything  not at all      never    65.0   \n",
       "11      28         average    mostly anything    socially      never    72.0   \n",
       "...    ...             ...                ...         ...        ...     ...   \n",
       "59935   33           curvy           anything    socially      never    67.0   \n",
       "59936   25         average    mostly anything    socially      never    61.0   \n",
       "59942   24             fit    mostly anything       often  sometimes    72.0   \n",
       "59943   42         average    mostly anything  not at all      never    71.0   \n",
       "59944   27        athletic    mostly anything    socially      often    73.0   \n",
       "\n",
       "      sex          smokes  \n",
       "0       m       sometimes  \n",
       "1       m              no  \n",
       "7       f              no  \n",
       "9       m              no  \n",
       "11      m              no  \n",
       "...    ..             ...  \n",
       "59935   f   when drinking  \n",
       "59936   f              no  \n",
       "59942   m              no  \n",
       "59943   m              no  \n",
       "59944   m  trying to quit  \n",
       "\n",
       "[25202 rows x 8 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NaN values\n",
    "working_df = working_df.dropna()\n",
    "working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'body_type', 'diet', 'drinks', 'drugs', 'height', 'sex', 'smokes']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See what columns we're working with    \n",
    "\n",
    "list(working_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>height</th>\n",
       "      <th>sex</th>\n",
       "      <th>smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>75.0</td>\n",
       "      <td>m</td>\n",
       "      <td>sometimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>70.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>average</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>65.0</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37</td>\n",
       "      <td>athletic</td>\n",
       "      <td>anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>65.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28</td>\n",
       "      <td>average</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>72.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59935</th>\n",
       "      <td>33</td>\n",
       "      <td>curvy</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>67.0</td>\n",
       "      <td>f</td>\n",
       "      <td>when drinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59936</th>\n",
       "      <td>25</td>\n",
       "      <td>average</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>61.0</td>\n",
       "      <td>f</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59942</th>\n",
       "      <td>24</td>\n",
       "      <td>fit</td>\n",
       "      <td>anything</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>72.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59943</th>\n",
       "      <td>42</td>\n",
       "      <td>average</td>\n",
       "      <td>anything</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>71.0</td>\n",
       "      <td>m</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59944</th>\n",
       "      <td>27</td>\n",
       "      <td>athletic</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>often</td>\n",
       "      <td>73.0</td>\n",
       "      <td>m</td>\n",
       "      <td>trying to quit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25124 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age       body_type      diet      drinks      drugs  height sex  \\\n",
       "0       22  a little extra  anything    socially      never    75.0   m   \n",
       "1       35         average     other       often  sometimes    70.0   m   \n",
       "7       31         average  anything    socially      never    65.0   f   \n",
       "9       37        athletic  anything  not at all      never    65.0   m   \n",
       "11      28         average  anything    socially      never    72.0   m   \n",
       "...    ...             ...       ...         ...        ...     ...  ..   \n",
       "59935   33           curvy  anything    socially      never    67.0   f   \n",
       "59936   25         average  anything    socially      never    61.0   f   \n",
       "59942   24             fit  anything       often  sometimes    72.0   m   \n",
       "59943   42         average  anything  not at all      never    71.0   m   \n",
       "59944   27        athletic  anything    socially      often    73.0   m   \n",
       "\n",
       "               smokes  \n",
       "0           sometimes  \n",
       "1                  no  \n",
       "7                  no  \n",
       "9                  no  \n",
       "11                 no  \n",
       "...               ...  \n",
       "59935   when drinking  \n",
       "59936              no  \n",
       "59942              no  \n",
       "59943              no  \n",
       "59944  trying to quit  \n",
       "\n",
       "[25124 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove inaccurate ages\n",
    "\n",
    "working_df = working_df[working_df.age != 109]\n",
    "working_df = working_df[working_df.age != 111]\n",
    "\n",
    "# Combine data that makes sense\n",
    "working_df = working_df.replace({'diet':{'strictly anything': 'anything',\n",
    "        'mostly anything': 'anything',\n",
    "        'strictly halal': 'halal',\n",
    "        'mostly halal':'halal',\n",
    "        'strictly kosher': 'kosher',\n",
    "        'mostly kosher':'kosher',\n",
    "        'strictly vegan':'vegan',\n",
    "        'mostly vegan': 'vegan',\n",
    "        'strictly vegetarian':'vegetarian',\n",
    "        'mostly vegetarian':'vegetarian',\n",
    "        'strictly other': 'other',\n",
    "        'mostly other': 'other'}})\n",
    "\n",
    "\n",
    "# Remove values that have declined to answer, since they will be unhelpful        \n",
    "\n",
    "values = ['declined to answer']        \n",
    "\n",
    "working_df = working_df[working_df.age.isin(values) == False]\n",
    "working_df = working_df[working_df.diet.isin(values) == False]\n",
    "working_df = working_df[working_df.body_type.isin(values) == False]\n",
    "working_df = working_df[working_df.drinks.isin(values) == False]\n",
    "working_df = working_df[working_df.drugs.isin(values) == False]\n",
    "working_df = working_df[working_df.height.isin(values) == False]\n",
    "working_df = working_df[working_df.sex.isin(values) == False]\n",
    "working_df = working_df[working_df.smokes.isin(values) == False]\n",
    "working_df = working_df[working_df.body_type != 'rather not say']\n",
    "\n",
    "working_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df.to_csv('gender_guesser_cleaned',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average           6802\n",
       "fit               5742\n",
       "athletic          5366\n",
       "thin              2191\n",
       "curvy             1843\n",
       "a little extra    1312\n",
       "skinny             804\n",
       "full figured       464\n",
       "overweight         227\n",
       "jacked             191\n",
       "used up            182\n",
       "Name: body_type, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique body type values\n",
    "working_df['body_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there is an extreme amount of average values, as compared to overweight & jacked, then we can assume that our model will be more inclined to predict average body types as opposed to the other types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit           11299\n",
       "average        6802\n",
       "curvy          3619\n",
       "thin           2995\n",
       "overweight      227\n",
       "used up         182\n",
       "Name: body_type, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up body type values\n",
    "cleaned_BT_df = working_df.replace({'body_type': {'athletic':'fit', 'full figured':'curvy', 'a little extra':'curvy', 'jacked':'fit', 'skinny':'thin'}})\n",
    "cleaned_BT_df['body_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no                20349\n",
       "sometimes          1679\n",
       "when drinking      1425\n",
       "yes                1023\n",
       "trying to quit      648\n",
       "Name: smokes, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique values of diet\n",
    "cleaned_BT_df['smokes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26    1577\n",
       "27    1533\n",
       "25    1441\n",
       "28    1396\n",
       "24    1382\n",
       "29    1325\n",
       "30    1264\n",
       "23    1176\n",
       "31    1091\n",
       "32    1037\n",
       "22     906\n",
       "33     883\n",
       "34     747\n",
       "35     676\n",
       "21     623\n",
       "36     616\n",
       "37     582\n",
       "38     534\n",
       "20     491\n",
       "39     446\n",
       "42     433\n",
       "41     409\n",
       "40     391\n",
       "43     362\n",
       "19     301\n",
       "44     289\n",
       "45     280\n",
       "46     226\n",
       "48     223\n",
       "47     213\n",
       "49     201\n",
       "50     194\n",
       "52     173\n",
       "18     165\n",
       "51     155\n",
       "54     133\n",
       "56     130\n",
       "53     116\n",
       "59     113\n",
       "57     108\n",
       "55     107\n",
       "61      96\n",
       "58      96\n",
       "60      94\n",
       "62      77\n",
       "63      68\n",
       "65      57\n",
       "66      57\n",
       "64      55\n",
       "67      30\n",
       "68      27\n",
       "69      19\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_BT_df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25124, 8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_BT_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Target Data = Body Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset into data and target\n",
    "X = cleaned_BT_df.drop(['body_type'], axis=1)\n",
    "y = cleaned_BT_df['body_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 2, 0, 2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do get dummies for data and label encoder for target\n",
    "X_dummies = pd.get_dummies(X)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "y_label = LabelEncoder().fit_transform(cleaned_BT_df['body_type'])\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dummies, y_label,test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7518707212227352\n",
      "Testing Score: 0.4005731571405827\n"
     ]
    }
   ],
   "source": [
    "# Test with Random Forest to see how well it works\n",
    "\n",
    "RF_clf = RandomForestClassifier(n_estimators=500).fit(X_train, y_train)\n",
    "print(f'Training Score: {RF_clf.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {RF_clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Random Forest, the Training went pretty well, but the resulting testing score was horrible. Unsure if it's because of the data or if it's because of the model.\n",
    "We'll test it with other models and see how those results pan out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.45820729183251074\n",
      "Testing Data Score: 0.45597834739691134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ruby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Test with Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_clf = LogisticRegression()\n",
    "\n",
    "LR_clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {LR_clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {LR_clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Logistic Regression, even though there's more than one target data, just to see how it fares, it results in both training and testing being giving horrible results. This is most likely due to the model being better suited to work with target datas with two values (i.e. \"Yes\" & \"No\")\n",
    "\n",
    "For now, we'll try using Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler instance\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "\n",
    "X_scaler = skl.preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Keras Sequential model\n",
    "nn_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our first Dense layer, including the input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"relu\", input_dim=X_train_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "activation = softmax\n",
    "Softmax is like Sigmoid but for more than 2 categories.\n",
    "Sigmoid is for predicting 0 and 1 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 5)                 125       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 131\n",
      "Trainable params: 131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the Sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss = categorical_crossentropy\n",
    "categorical is for more than 2 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 2/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 3/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 4/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 5/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 6/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 7/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 8/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 9/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 10/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 11/100\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 12/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 13/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 14/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 15/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 16/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 17/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 18/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 19/100\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 20/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 21/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 22/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 23/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 24/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 25/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 26/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 27/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 28/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 29/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 30/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 31/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 32/100\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 33/100\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 34/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 35/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 36/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 37/100\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 38/100\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 39/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 40/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 41/100\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 42/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 43/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 44/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 45/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 46/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 47/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 48/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 49/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 50/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 51/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 52/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 53/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 54/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 55/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 56/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 57/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 58/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 59/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 60/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 61/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 62/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 63/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 64/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 65/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 66/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 67/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 68/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 69/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 70/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 71/100\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 72/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 73/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 74/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 75/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 76/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 77/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 78/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 79/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 80/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 81/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 82/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 83/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 84/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 85/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 86/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 87/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 88/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 89/100\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 90/100\n",
      "393/393 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 91/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 92/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 93/100\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 94/100\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 95/100\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 96/100\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 97/100\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 98/100\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 99/100\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n",
      "Epoch 100/100\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - accuracy: 0.1422\n"
     ]
    }
   ],
   "source": [
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model to the training data\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So even with the Neural Networking, the score plateau'd and stayed consistently at low accuracy. This is looking more like an issue with the data rather than the models since it's bad with each selected model so far.\n",
    "\n",
    "To switch things up, instead of body types, I'll switch the target data to be the Sex instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataset into data and target\n",
    "X = cleaned_BT_df.drop(['sex'], axis=1)\n",
    "y = cleaned_BT_df['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do get dummies for data and label encoder for target\n",
    "X_dummies = pd.get_dummies(X)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "y_label = LabelEncoder().fit_transform(cleaned_BT_df['sex'])\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dummies, y_label,test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9369527145359019\n",
      "Testing Score: 0.8183410284986468\n"
     ]
    }
   ],
   "source": [
    "# Test with Random Forest to see how well it works\n",
    "\n",
    "RF_clf = RandomForestClassifier(n_estimators=500).fit(X_train, y_train)\n",
    "print(f'Training Score: {RF_clf.score(X_train, y_train)}')\n",
    "print(f'Testing Score: {RF_clf.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, the accuracy is great when the models are subjected to pick either Male or Female. Perhaps it's because of it's requiring to pick between two values instead of six? For consistency sake, I'll rerun the other models as well to see if RandomForest's good scores were a fluke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8364113994586849\n",
      "Testing Data Score: 0.8420633657060977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ruby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Test with Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_clf = LogisticRegression()\n",
    "\n",
    "LR_clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training Data Score: {LR_clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {LR_clf.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler instance\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "\n",
    "X_scaler = skl.preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Keras Sequential model\n",
    "nn_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our first Dense layer, including the input layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=5, activation=\"relu\", input_dim=X_train_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the output layer that uses a probability activation function\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 5)                 145       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151\n",
      "Trainable params: 151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the structure of the Sequential model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.6397 - accuracy: 0.6750\n",
      "Epoch 2/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.7981\n",
      "Epoch 3/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3915 - accuracy: 0.8296\n",
      "Epoch 4/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8382\n",
      "Epoch 5/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3645 - accuracy: 0.8412\n",
      "Epoch 6/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3617 - accuracy: 0.8421\n",
      "Epoch 7/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8436\n",
      "Epoch 8/50\n",
      "393/393 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8438\n",
      "Epoch 9/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3583 - accuracy: 0.8442\n",
      "Epoch 10/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3579 - accuracy: 0.8437\n",
      "Epoch 11/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3571 - accuracy: 0.8441\n",
      "Epoch 12/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3566 - accuracy: 0.8440\n",
      "Epoch 13/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3557 - accuracy: 0.8451\n",
      "Epoch 14/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3551 - accuracy: 0.8448\n",
      "Epoch 15/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3550 - accuracy: 0.8454\n",
      "Epoch 16/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3544 - accuracy: 0.8455\n",
      "Epoch 17/50\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.3544 - accuracy: 0.8452\n",
      "Epoch 18/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3541 - accuracy: 0.8468\n",
      "Epoch 19/50\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.3541 - accuracy: 0.8465\n",
      "Epoch 20/50\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.3537 - accuracy: 0.8461\n",
      "Epoch 21/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3537 - accuracy: 0.8462\n",
      "Epoch 22/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3535 - accuracy: 0.8458\n",
      "Epoch 23/50\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8476\n",
      "Epoch 24/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3533 - accuracy: 0.8466\n",
      "Epoch 25/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3531 - accuracy: 0.8481\n",
      "Epoch 26/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3528 - accuracy: 0.8474\n",
      "Epoch 27/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3527 - accuracy: 0.8480\n",
      "Epoch 28/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3525 - accuracy: 0.8480\n",
      "Epoch 29/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3522 - accuracy: 0.8469\n",
      "Epoch 30/50\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.3515 - accuracy: 0.8484\n",
      "Epoch 31/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3519 - accuracy: 0.8484\n",
      "Epoch 32/50\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.3514 - accuracy: 0.8484\n",
      "Epoch 33/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3516 - accuracy: 0.8485\n",
      "Epoch 34/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3512 - accuracy: 0.8493\n",
      "Epoch 35/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3513 - accuracy: 0.8480\n",
      "Epoch 36/50\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.3511 - accuracy: 0.8492\n",
      "Epoch 37/50\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.3509 - accuracy: 0.8484\n",
      "Epoch 38/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3510 - accuracy: 0.8480\n",
      "Epoch 39/50\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.3510 - accuracy: 0.8485\n",
      "Epoch 40/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3508 - accuracy: 0.8485\n",
      "Epoch 41/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3504 - accuracy: 0.8484\n",
      "Epoch 42/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3506 - accuracy: 0.8492\n",
      "Epoch 43/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3507 - accuracy: 0.8483\n",
      "Epoch 44/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3502 - accuracy: 0.8474\n",
      "Epoch 45/50\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.3502 - accuracy: 0.8484\n",
      "Epoch 46/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3503 - accuracy: 0.8486\n",
      "Epoch 47/50\n",
      "393/393 [==============================] - 1s 2ms/step - loss: 0.3502 - accuracy: 0.8493\n",
      "Epoch 48/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3501 - accuracy: 0.8501\n",
      "Epoch 49/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3500 - accuracy: 0.8498\n",
      "Epoch 50/50\n",
      "393/393 [==============================] - 1s 1ms/step - loss: 0.3500 - accuracy: 0.8488\n"
     ]
    }
   ],
   "source": [
    "# Compile the Sequential model together and customize metrics\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model to the training data\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our target data being Sex, we managed to have a higher accuracy score for all three models. It's interesting since this having less target values to predict might be better, in correlation with the data we have. With having more target values, in this case the body types, the models we selected did poorly regarding predicting the correct body types. In the future, we might test with more models to see if the there are any that are more compatible with our data, or if we can clean this to be more concise so we can introduce more variables that may help with future predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e246d2215c418239c9316a1ebf2d8abb44dc50b2e5b0e29defd87143398aa387"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
